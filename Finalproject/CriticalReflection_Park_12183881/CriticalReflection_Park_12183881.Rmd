---
output:
  bookdown::pdf_document2:
    number_sections: true
    highlight: tango
    toc: false
bibliography: references.bib
csl: "apa.csl"
link-citations: yes
urlcolor: blue
#linkcolor: blue
toccolor: "black"


#geometry: margin = 2cm
#fontsize: 11.5pt
mainfont: Calibri
sansfont: Calibri
indent: true
header-includes:
  - \usepackage{indentfirst, graphicx, caption, setspace, floatrow, tikz}
  - \usepackage{setspace}\spacing{1.5}
  - \setlength{\skip\footins}{0.5cm}
  - \captionsetup[table]{skip=5pt}
  - \usepackage[singlelinecheck=false]{caption}
  - \floatsetup[figure]{capposition=top}
  - \floatsetup[table]{capposition=top}
  - \usepackage[labelfont=bf]{caption}
  #- \usepackage[normalem]{ulem}

---

```{r setup, include=FALSE}
options(warn = -1) 
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      comment = NA,
                      fig.align = "center")
library(dplyr)
library(kableExtra)
library(ggplot2)
library(qgraph)
library(pcalg)

source("code/R/CCD_fnc.R")
source("code/R/plot_fnc.R")
source("code/R/dsep_fnc.R")
source("code/R/searchAM_KP_fnc.R")
source("code/R/equivset_fnc.R")
source("code/R/data_generating_fnc.R")
source("code/R/eval_metric_fnc.R")
source("code/R/variation_fnc.R")
```

\pagenumbering{gobble}

\includegraphics[width=0.7cm]{img/logouva.png}
\Large Individual Report

\begin{centering}
\vspace{1cm}
\LARGE
{\bf Critical Reflection on Comparison of Gaussian Graphical Model (GGM) and Directed Cyclic Graph Model (DCG) as Causal Discovery Tools}

\vspace{0.5cm}
\Large
Network Analysis 2022 \\

\vspace{1cm}
\Large
\textbf{Kyuri Park} (12183881) \\

December 22, 2022 \\
\vspace{0.5cm}
\large {Word count: 994}  

\vspace{1cm}

\end{centering}

\pagenumbering{arabic}
\normalsize

\vspace{1cm}
\setcounter{tocdepth}{2}
\renewcommand{\contentsname}{Table of Contents}
\tableofcontents

\newpage
# Summary of Final Project 

In our final project, we aimed to investigate the utility of statistical network models as tools for causal discovery in *cyclic* settings compared to the *directed cyclic graph* models (DCG) by means of a simulation study. 
We used *cyclic causal discovery* (CCD) algorithm to estimate DCGs [@richardson1996] and compare them to the Gaussian graphical models (GGM). The comparison is made based on the overall density of the model and degree centrality of each node. Note that the output of CCD is a PAG (*partial ancestral graph*)^[See Figure \@ref(fig:pag).], which represents the *Markov-equivalent* class of DCGs (i.e., it encompasses multiple DCGs that are statistically equivalent under the found conditional independencies in the data). Therefore, we computed the average density and average degree centrality per node for all equivalent DCGs and compared those to the density and degree centrality of GGM and true model, respectively.

The results found that the DCGs approximated the true cyclic models better in terms of both density and degree centrality compared to GGMs. GGM often overestimated the density and correspondingly resulted in high degree for almost all nodes in the considered models. The conclusion based on these results could be that statistical network model performs poorly as causal discovery tools in cyclic settings and hence, it shall be preferred to use a purpose-built *causal discovery methods* when one is interested in underlying causal mechanism.

\vspace{0.5cm}

```{r pag}
#| echo = FALSE,
#| fig.cap= "(ref:pag)",
#| fig.align='center',
#| out.width="101%",
#| dpi=300
knitr::include_graphics("img/CCDsummary.png")
```
(ref:pag) Example partial ancestral graph.  

\vspace{-0.3cm}
\setstretch{1.0}
\noindent\small\textit{\textbf{Note.}} Given the found statistical independencies from the true graph, CCD outputs a partial ancestral graph (PAG). It can be seen that in this example, the PAG represents two different directed cyclic graphs (DCG), of which we compute the density and degree centrality. Then, the average value of density and degree centrality are subsequently used for comparison with the GGM.

\normalsize
\setstretch{1.5}

# Reflection on Limitations

\noindent However, we cannot just naively draw such conclusion merely based on these results, as there are several limitations in this simulation study. Below, I list two crucial limitations in my opinion.

1.	We did not explicitly account for the *uncertainty* in estimation with CCD. As explained above, CCD in general cannot uniquely identify one true graph, but instead provides a set of equivalent DCGs (as a form of PAG). The size of the equivalent class thus reflects the uncertainty in its estimation. It is a critical aspect to further investigate, as it could be the case that even when the average density and average degree centrality are closely aligned to those of the true model, the *variation* in the set is huge, implying a high uncertainty/instability in estimation. 

2.	There is little evidence on practical applicability of CCD, as we only tested it out on rather small simulated models  ($p = 4, 5, 6$) with a very large sample size ($N = 10^6$). The typical psychological data, however, usually consist of much less observations while including more variables [@constantin_general_2021]. Thus, whether CCD can be applied to such data and utilized in psychological research in practice is yet questionable.

# Further Extensions

 To examine the overall uncertainty and variation in estimation as to the first limitation, we check the size of equivalent class from each of the considered models and investigate the variation in the density as well as in degree centrality per each set of DCGs. Regarding the practical applicability of CCD, we test the CCD algorithm on an empirical data [@mcnally2017] and check if it produces a reasonable output. Here, we focus on discussing the analysis results only on the first limitation. For the results on the applicability of CCD in practice, we refer the interested readers to Appendix (section \@ref(appendix)).

## Variation in Density of DCGs
Figure \@ref(fig:density-variation) shows the size of equivalence class and the distribution of density per the set of DCGs from each of the considered models. First thing that stands out is that dense models (right column of Figure \@ref(fig:density-variation)) seem to have a slightly higher variation in density (i.e., spread of distribution is wider) and accordingly the discrepancy between the true and average density of DCGs is larger in dense models than in the sparse models. This indicates that when the variation is high in the estimated densities, the average density of DCGs is unlikely to approximate the true density well. Hence, it is not probable that the average density of DCGs follow the true density closely, while having a high variance in the set of densities. 

Secondly, it could be seen that the size of equivalence class is overall quite large, except for the *sparse model with 4 nodes* (Figure \@ref(fig:density-variation) (a)). There is no specific pattern observed between the size of equivalence class and the types of models, but these overall fairly large equivalence classes suggest the lack of certainty in estimation with CCD, which is actually known as one of the weaknesses of the causal discovery algorithms [@bongers_theoretical_2016].

\vspace{0.5cm}

```{r density-variation}
#| echo = FALSE,
#| fig.cap= "(ref:density-variation)",
#| out.width = "77%",
#| fig.align='center',
#| dpi=600
knitr::include_graphics("img/density_variation.pdf")
```
(ref:density-variation) Distribution of density per the set of DCGs.  


\vspace{-0.3cm}
\setstretch{1.0}
\noindent\small\textit{\textbf{Note.}} The scale of x-axis is fixed the same across the graphs so that the comparison between distributions (e.g., spread) can be easily made. In (a), both DCGs in the equivalence class have the same density that is identical to the true density (the two lines overlap). The dense model with 4 nodes (b) seems to be the most difficult case for CCD, given that it has the largest equivalence class (1,659 DCGs) with the highest discrepancy in density among all considered cases. In general, CCD struggles more to estimate the dense models, since in the dense cases, there are more variations in densities with larger discrepancies in comparison to the sparse models. 

\normalsize

\setstretch{1.5}



## Variation in Degree Centrality of DCGs
 Figure \@ref(fig:deg-variation) shows the average degree per node with 95% confidence interval in each of the considered models. Here, we see that the 95% confidence intervals in the dense models are relatively wider than the ones in the sparse models, which indicate that there are more uncertainty in degree estimation with dense models. This is in accordance with the variation in density as shown in Figure \@ref(fig:density-variation), where the dense models are shown to have more variations in the overall density estimation. 
 
 All in all, with these additional analyses, we learn that the variation in estimation with CCD tends to become higher when the models are dense. But as the variation becomes larger, the average density/degree also deviates more from the true value. Thus, it is not likely that the average density/degree closely follows the true density/degree in the cases with high variance. However, we still need to keep in mind the rather general limitation that there typically exists a considerable size of equivalence class and correspondingly need to think of what that implies for one's analysis, when using the causal discovery algorithms.

\vspace{0.5cm}

```{r deg-variation}
#| echo = FALSE,
#| fig.cap= "(ref:deg-variation)",
#| out.width = "90%",
#| fig.align='center',
#| dpi=600
knitr::include_graphics("img/deg_variation.pdf")
```
(ref:deg-variation) Average degree per node with 95% confidence interval. 

\vspace{-0.3cm}
\setstretch{1.0}
\noindent\small\textit{\textbf{Note.}} In (a), the standard error (SE) is zero and accordingly confidence interval (CI) doesn't exist. For the rest, the values of SE are also very small (0.01 - 0.01), which makes it hard to visualize CIs. For the ease of comparison, the SEs are scaled up. Hence, note that the width of CIs can only be compared across different cases in a relative sense.
 
\normalsize
\setstretch{1.5}


\newpage
# Conclusion
 In this project, we aimed to clarify the role of statistical network models (GGM) as causal discovery tools in cyclic settings compared to the directed cyclic graph models (DCG) estimated by CCD algorithm. Overall, the results indicate that GGMs are not suitable for inferring causal structure with cycles. Even though, CCD comes with a couple of limitations as previously discussed, the limitation is not deemed to be detrimental and it is still considered more useful when it comes to modeling a causal structure, as it can approximate the causal relations more accurately. 
 
 Note that it does not state that the statistical network models are completely uninformative in this regard. Statistical models can provide additional information such as the sign and strength of relationships [@epskamp_gaussian_2018] and also visualize clustering structures nicely [@golino_exploratory_2017], which can be useful. However, when it comes to identifying causal relations, the statistical network models come up short, as our simulation study showed. Accordingly, when one is interested in the network approach to search for causal mechanism, then the focus should be on estimating a causal model such as DCGs rather than statistical network models.



# References
<div id="refs"></div>

\newpage
# Appendix {#appendix}

Figure \@ref(fig:mcnallypag) shows the partial ancestral graph (PAG) for depression symptoms estimated by CCD algorithm based on the data provided by @mcnally2017. A couple of features are apparent. First, there are two clusters (islands), one comprising symptoms related to sleeping problems, and the other comprising symptoms related to appetite issue. Secondly, there exists a cycle (feedback loop): `anhedonia` $\rightarrow$ `fatigue` $\rightarrow$ `retard` $\rightarrow$ `sad` $\rightarrow$ `anhedonia`, which seems reasonable in a substantive sense. Here, we do not know the true model but the overall findings from this causal model is deemed rather informative and sensible. Given this, it can be concluded that CCD is indeed applicable in practice to typical psychological data and can be used to help discovering some interesting causal dynamics in psychological processes.

Just for a comparison, the statistical network model (GGM) is also estimated using graphical LASSO [@epskamp_tutorial_2018] as shown in Figure \@ref(fig:mcnallynetwork). In accordance with the causal model, similar clustering structures are observed with symptoms related to sleep and appetite. Even though here with the statistical network model, we could additionally examine the sign (positive/negative) and the strength of relations between symptoms, we can hardly infer any causal relations or detect the presence of feedback loops, as we did in the causal model.

\vspace{0.5cm}

\newcommand{\udensdot}[1]{
    \tikz[baseline=(todotted.base)]{
        \node[inner sep=1pt,outer sep=0pt] (todotted) {#1};
        \draw[densely dotted] (todotted.south west) -- (todotted.south east);
    }
}


```{r mcnallypag}
#| echo = FALSE,
#| results = 'hide',
#| fig.height = 4,
#| fig.width = 5,
#| fig.cap = "PAG estimated by CCD algorithm for depression symptoms."
## empirical data example
# import data
mcnally <- read.csv("data/McNally.csv")
# separate dep / ocd symptoms
depression <- mcnally[,1:16]
ocd <- mcnally[,17:26]

# estimat PAG on depression symptoms (run CCD)
ccd_mcnally_dep <- ccdKP(df=depression, dataType = "discrete", depth = -1)
mat_mcnally_dep <- CreateAdjMat(ccd_mcnally_dep, p = ncol(depression))
pag_mcnally_dep <- plotPAG(ccd_mcnally_dep, mat_mcnally_dep)
```

\vspace{-0.1cm}
\setstretch{1.0}
\noindent\small\textit{\textbf{Note.}} In the PAG representation, there exists two types of underlining that can be used in a triple of nodes: solid underlining ($\text{A - {\underline{B} - C}}$) and dotted underlining ($\text{A - {\udensdot{B} - C}}$). The colored nodes (in blue) refer to the presence of the solid underlining and the dashed nodes refer to the presence of the dotted underlining on the corresponding nodes. These underlines are used to further orient the edges in a PAG. For more information on this, see @Richardson1996a.
 
\normalsize
\setstretch{1.5}

```{r mcnallynetwork}
#| echo = FALSE,
#| results = 'hide',
#| fig.height = 4,
#| fig.width = 5,
#| fig.cap = "Statistical network model constructed via graphical LASSO for depression symptoms."

# estimate network model for depression symptoms (graphical LASSO)
cordep <- cor(depression)
glassoFitdep <- EBICglasso(cordep, n = nrow(depression), gamma = 1)
qgraph(glassoFitdep, layout = "spring", theme="colorblind", nodeNames = colnames(depression), legend.cex = 0.4)
```
